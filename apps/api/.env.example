PORT=8080
ALLOWED_ORIGINS=http://localhost:5173
DEMO_MODE=false

# choose provider explicitly
LLM_PROVIDER=ollama
# or: LLM_PROVIDER=openai

# explicit fallback behavior (optional)
FALLBACK_PROVIDER=demo
# or: FALLBACK_PROVIDER=none

# openai settings (only needed if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=gpt-4o-mini

# ollama settings (only needed if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# shared timeout
LLM_TIMEOUT_MS=12000